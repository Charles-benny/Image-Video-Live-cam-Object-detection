{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86ffec62-7364-47c7-b7b7-07b7f474fa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\charl\\anaconda3\\lib\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\charl\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78536472-3e78-425c-8597-550152267b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10f93b6b-6383-416c-9a94-9441ed3b4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = './ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "frozen_model = './frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2f8156a-1d94-40ce-9c76-167620c050d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.dnn.Model 000001E71C33E030>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cv2.dnn_DetectionModel(frozen_model, config_file)\n",
    "\n",
    "model.setInputSize(320, 320)\n",
    "model.setInputScale(1.0 / 127.5)\n",
    "model.setInputMean((127.5, 127.5, 127.5))\n",
    "model.setInputSwapRB(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e76e80cc-c1cd-4958-bfbf-547a80b1dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lable=[]\n",
    "file_name='coco.txt'\n",
    "with open(file_name,'rt')as fpt:\n",
    "    lable=fpt.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cd58283-1fb3-42f5-8499-b5fcac1d6240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f660af1-cc23-4df6-a2d3-859b1a1bebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(lable))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e50d9b-26fc-4a19-b588-08e944b74e7d",
   "metadata": {},
   "source": [
    "Reading Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7cc0116-61bb-4efe-bffc-a9147ffb112a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image not found or could not be read.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not found or could not be read.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Image not found or could not be read."
     ]
    }
   ],
   "source": [
    "image_path = '.jpg'  # Path to test image\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise ValueError(\"Image not found or could not be read.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3731a-1604-483a-9945-6877b90ebf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path=cv2.imread('lorry.jpg')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed743d3e-7721-49de-a90c-b71a92710272",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892017a1-9df4-411e-bfbd-6796c09d52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf1deb-7609-4038-8d9a-2d41cfaeea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassIndex, confidece, bbox=model.detect(image,confThreshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2496fe3-2dc9-4fd3-9dfe-41a803bda6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ClassIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cca52c-de81-41cb-8bf3-01dddd23a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(n_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109a851-4056-456c-bc8a-3167d70ca915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids, confidences, boxes = model.detect(image, confThreshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4e650-b181-42a8-92fb-4cb8c56d3367",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_scale = 1\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "for class_id, confidence, box in zip(class_ids.flatten(), confidences.flatten(), boxes):\n",
    "    cv2.rectangle(image, box, (255, 0, 0), 1)\n",
    "    cv2.putText(image, f'{lable[class_id - 1]}: {confidence:.2f}', (box[0] + 10, box[1] + 30), font, fontScale=font_scale, color=(0, 250, 0), thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c2f3e-4897-4b1c-b9bf-964cd508200e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd1c92-cfd4-4138-a857-f45dfa422265",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d550d29-1c9c-4709-b143-36ee8e4b5f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
